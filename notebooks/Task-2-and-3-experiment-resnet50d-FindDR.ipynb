{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAC2022 Task 2 and 3 Experiment Notebook\n",
    "* creator: Jungrae Cho (team: FindDR)\n",
    "* created: November 25 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh import changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import gc\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from natsort import natsorted\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from skimage import io, color\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameters(num_classes, batch_size, and seed) and Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size dict\n",
    "img_size_dict = {\n",
    "    \"resnet50d\":224,\n",
    "    \"efficientnet_b3a\":320,\n",
    "    \"efficientnet_b3\":300,\n",
    "    \"skresnext50_32x4d\":288,\n",
    "    \"seresnext50d_32x4d\":224\n",
    "}\n",
    "\n",
    "# parpameters\n",
    "GPU_NUM = 1\n",
    "BATCH_SIZE = 32\n",
    "TASK_NUM = 1 # Task 2: 1, Task 3: 2\n",
    "SEED = 42\n",
    "EPOCHS = 20\n",
    "MODEL_NAME = \"resnet50d\" # choose one from resnet50d, efficientnet_b3a, efficientnet_b3, skresnext50_32x4d, or seresnext50d_32x4d\n",
    "IMG_SIZE = img_size_dict[MODEL_NAME]\n",
    "\n",
    "experiment_name = f\"timm-{MODEL_NAME}-drac2022-task{TASK_NUM+1}\"\n",
    "num_classes = 3 \n",
    "original_height = IMG_SIZE\n",
    "original_width = IMG_SIZE\n",
    "\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download DRAC2022 dataset checkt out its directory structure.\n",
    "\n",
    "Dataset structure should be like this:\n",
    "```\n",
    "./DRAC2022_Data_Set/\n",
    "    ├── DRAC2022_Testing_Set\n",
    "    │   ├── A. Segmentation\n",
    "    │   │   └── 1. Original Images\n",
    "    │   │       └── b. Testing Set\n",
    "    │   ├── B. Image Quality Assessment\n",
    "    │   │   └── 1. Original Images\n",
    "    │   │       └── b. Testing Set\n",
    "    │   └── C. Diabetic Retinopathy Grading\n",
    "    │       └── 1. Original Images\n",
    "    │           └── b. Testing Set\n",
    "    └── DRAC2022_Training_Set\n",
    "        ├── A. Segmentation\n",
    "        │   ├── 1. Original Images\n",
    "        │   │   └── a. Training Set\n",
    "        │   └── 2. Groundtruths\n",
    "        │       └── a. Training Set\n",
    "        │           ├── 1. Intraretinal Microvascular Abnormalities\n",
    "        │           ├── 2. Nonperfusion Areas\n",
    "        │           └── 3. Neovascularization\n",
    "        ├── B. Image Quality Assessment\n",
    "        │   ├── 1. Original Images\n",
    "        │   │   └── a. Training Set\n",
    "        │   └── 2. Groundtruths\n",
    "        └── C. Diabetic Retinopathy Grading\n",
    "            ├── 1. Original Images\n",
    "            │   └── a. Training Set\n",
    "            └── 2. Groundtruths\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"DRAC2022_Data_Set/\" # Specifiy directory of DRAC2022 dataset.\n",
    "\n",
    "img_paths = glob(os.path.join(data_root, \"*\",\"*\",\"*\",\"*\",\"*.png\")) # path of images\n",
    "seg_paths = glob(os.path.join(data_root, \"*\",\"*\",\"*\",\"*\",\"*\",\"*.png\")) # path of labels\n",
    "csv_paths = glob(os.path.join(data_root, \"*\",\"*\",\"*\",\"*.csv\")) # path of labels\n",
    "\n",
    "print(len(img_paths), len(csv_paths), len(seg_paths))\n",
    "print(img_paths[0])\n",
    "print(seg_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = img_paths[0].split(\"/\")\n",
    "task = parser[-4]\n",
    "data_split = parser[-2]\n",
    "file_name = parser[-1]\n",
    "print(f\"{task}, {data_split}, {file_name}\")\n",
    "\n",
    "tasks = []\n",
    "data_splits = []\n",
    "file_names =[]\n",
    "for img_path in tqdm(img_paths):\n",
    "    parser = img_path.split(\"/\")\n",
    "    task = parser[-4]\n",
    "    data_split = parser[-2]\n",
    "    file_name = parser[-1]\n",
    "    tasks.append(task)\n",
    "    data_splits.append(data_split)\n",
    "    file_names.append(file_name)\n",
    "tasks = sorted(list(set(tasks))) \n",
    "data_splits = sorted(list(set(data_splits)))\n",
    "print(\"\\n\")\n",
    "print(tasks)\n",
    "print(data_splits)\n",
    "print(len(file_names))\n",
    "\n",
    "task_img_count = {kk:{k:0 for k in tasks} for kk in data_splits}\n",
    "\n",
    "for img_path in tqdm(img_paths):\n",
    "    parser = img_path.split(\"/\")\n",
    "    task = parser[-4]\n",
    "    data_split = parser[-2]\n",
    "    task_img_count[data_split][task] += 1\n",
    "print(\"\\n\")\n",
    "print(task_img_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {\n",
    "    \"train\":[],\n",
    "    \"test\":[]\n",
    "}\n",
    "for img_path in img_paths:\n",
    "    if tasks[TASK_NUM] in img_path:\n",
    "        if data_splits[0] in img_path:\n",
    "            data_paths[\"train\"].append(img_path)\n",
    "        else:\n",
    "            data_paths[\"test\"].append(img_path)\n",
    "            \n",
    "for k, v in data_paths.items():\n",
    "    print(k,\":\", len(v))\n",
    "    data_paths[k] = natsorted(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(csv_paths[TASK_NUM-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    return np.eye(num_classes, dtype='uint8')[y]\n",
    "\n",
    "class DRAC2022ClassificationDataset(object):\n",
    "    def __init__(self, data_paths, csv_path, transforms, mode, num_classes):\n",
    "        self.mode = mode\n",
    "        self.num_classes = num_classes\n",
    "        self.imgs = data_paths[self.mode]\n",
    "        self.labels = pd.read_csv(csv_path)\n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img = cv2.imread(self.imgs[idx],-1).astype(np.uint8)\n",
    "        img = np.stack([img,img,img], -1)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "\n",
    "            file_name = self.imgs[idx].split('/')[-1]\n",
    "            if TASK_NUM == 1:\n",
    "                label = labels[labels[\"image name\"]==file_name][\"image quality level\"].values\n",
    "            else:\n",
    "                label = labels[labels[\"image name\"]==file_name][\"DR grade\"].values\n",
    "\n",
    "\n",
    "            if self.transforms is not None:\n",
    "                transformed = self.transforms(image=img)\n",
    "                img = transformed['image'] / 255\n",
    "\n",
    "                img = torch.from_numpy(img).permute(2,1,0).float()\n",
    "                label = torch.as_tensor(label, dtype=torch.int64)\n",
    "#                 label = to_categorical(label,self.num_classes)\n",
    "#                 label = torch.from_numpy(label).long()\n",
    "\n",
    "            return img, label\n",
    "       \n",
    "        else:\n",
    "            \n",
    "            if self.transforms is not None:\n",
    "                transformed = self.transforms(image=img)\n",
    "                img = transformed['image'] / 255\n",
    "\n",
    "                img = torch.from_numpy(img).permute(2,1,0).float()\n",
    "                \n",
    "            return img, _\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    if train:\n",
    "        aug = A.Compose([\n",
    "            A.Resize(original_height, original_width,p=1),\n",
    "            A.Normalize(p=0.1),    \n",
    "            A.VerticalFlip(p=0.5),              \n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5)\n",
    "        ])\n",
    "    else:\n",
    "        aug = A.Compose([\n",
    "            A.Resize(original_width, original_height,p=1),\n",
    "            A.Normalize(p=0.1)\n",
    "        ])\n",
    "    return aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DRAC2022ClassificationDataset(data_paths, csv_paths[TASK_NUM-1], get_transform(True), 'train', num_classes)\n",
    "dataset_test = DRAC2022ClassificationDataset(data_paths, csv_paths[TASK_NUM-1], get_transform(False), 'train', num_classes)\n",
    "\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "train_set = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "test_set = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=BATCH_SIZE, num_workers=4, drop_last=True)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.size(), img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw = DRAC2022ClassificationDataset(data_paths, csv_paths[TASK_NUM-1], None, 'train', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = dataset_raw.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "targets = []\n",
    "perms = np.random.permutation(np.arange(dataset_raw.__len__()))\n",
    "for j in range(0,3):\n",
    "    for i in perms:\n",
    "        img, target = dataset_raw.__getitem__(i)\n",
    "        if target.item() == j:\n",
    "            imgs.append(img)\n",
    "            targets.append(target.item())\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(14,5))\n",
    "# plt.suptitle(f\"{seg_labels[i]}\", y=0.9)\n",
    "for i, img in enumerate(imgs):\n",
    "    ax[i].imshow(img, cmap='gray')\n",
    "    ax[i].axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "class LitModel(LightningModule):\n",
    "    def __init__(self, num_classes,\n",
    "                 train_loader, val_loader, test_loader):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def to(self,device):\n",
    "        self.model.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y.squeeze(1))\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        loader = self.train_loader\n",
    "        return loader\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y.squeeze(1))\n",
    "        y_hat = y_hat.max(1)[1]\n",
    "        acc = accuracy(y_hat, y)\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss, 'val_acc':avg_acc}\n",
    "        return {'avg_val_loss': avg_loss, 'avg_val_acc': avg_acc,\n",
    "                'log': tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        loader = self.val_loader\n",
    "        return loader\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y.squeeze(1))\n",
    "        y_hat = y_hat.max(1)[1]\n",
    "        acc = accuracy(y_hat, y)\n",
    "        return {'test_loss': loss, 'test_acc': acc}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'test_loss': avg_loss, 'test_acc': avg_acc}\n",
    "        return {'avg_test_loss': avg_loss, 'avg_test_acc': avg_acc, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        loader = self.test_loader\n",
    "        return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set Random Seed and Create A Model Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# seed everything\n",
    "pl.seed_everything(SEED)\n",
    "\n",
    "# callbacks\n",
    "# early stopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   min_delta=0.00,\n",
    "   patience=20,\n",
    "   verbose=True,\n",
    "   mode='min'\n",
    ")\n",
    "logger = TensorBoardLogger('./lightning_logs', name=experiment_name)\n",
    "ckpt = ModelCheckpoint(os.path.join('./lightning_logs',\n",
    "                                    experiment_name,\n",
    "                                    f'version_{logger.version}',\n",
    "                                    'checkpoints'))\n",
    "\n",
    "callbacks = [ckpt]\n",
    "\n",
    "# define a model\n",
    "model = LitModel(num_classes,\n",
    "                 train_loader, test_loader, test_loader)\n",
    "\n",
    "#     from torchsummary import summary\n",
    "#     summary(model, (3, 256, 256))\n",
    "device = torch.device(f'cuda:{GPU_NUM}') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define trainer\n",
    "trainer = pl.Trainer(gpus=[GPU_NUM], max_epochs=EPOCHS, callbacks=callbacks,\n",
    "                    auto_lr_find=False)\n",
    "\n",
    "# train the model\n",
    "trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "# test the model\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "# clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "best_root = f\"./lightning_logs/{experiment_name}/\"\n",
    "print(best_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ckpt = natsorted(glob(os.path.join(best_root,\"*\",\"*\",\"*.ckpt\")))[-1]\n",
    "print(best_ckpt)\n",
    "best_model = model.load_from_checkpoint(best_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The implementation of Quadratic Weighted Kappa is from\n",
    "https://blog.csdn.net/qq_35447659/article/details/107468778\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b, min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j] / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "    return 1.0 - numerator / denominator\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    y_true = np.array([0, 0, 1, 2], dtype=int)\n",
    "    y_pred = np.array([0, 0, 1, 0], dtype=int)\n",
    "    y_scores = np.array([[0.55, 0.2, 0.25],\n",
    "                         [0.8, 0.1, 0.1],\n",
    "                         [0.1, 0.7, 0.2],\n",
    "                         [0.8, 0.1, 0.1]],\n",
    "                        dtype=np.float64)\n",
    "    Kw = quadratic_weighted_kappa(y_true, y_pred)\n",
    "    AUC = roc_auc_score(y_true, y_scores, average=\"macro\", multi_class='ovo')\n",
    "    print(Kw, AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_loader)\n",
    "best_model.eval()\n",
    "img_list = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_score = []\n",
    "for i in range(len(test_loader)):\n",
    "    img, gt = next(test_iter)\n",
    "    img_np = img.squeeze(0).permute(1,2,0).mul(255).detach().cpu().numpy().astype(np.uint8).copy()\n",
    "    img_list.append(img_np)\n",
    "    gt_np = gt.squeeze(0).numpy()\n",
    "    with torch.no_grad():\n",
    "        yhat = best_model(img)\n",
    "        yhat_np = yhat.max(1)[1].detach().cpu().numpy()\n",
    "        yhat_score = torch.softmax(yhat,-1).detach().cpu().numpy()\n",
    "        y_true.append(gt_np[0])\n",
    "        y_pred.append(yhat_np[0])\n",
    "        y_pred_score.append(yhat_score[0])\n",
    "y_true = np.array(y_true, dtype=int)\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "y_pred_score = np.array(y_pred_score, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "y_pred_score[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kw = quadratic_weighted_kappa(y_true, y_pred)\n",
    "AUC = roc_auc_score(y_true, y_pred_score, average=\"macro\", multi_class='ovo')\n",
    "Kw, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Export submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission data generation\n",
    "dataset_test_real = DRAC2022ClassificationDataset(data_paths, csv_paths[TASK_NUM-1], get_transform(False), 'test', num_classes)\n",
    "test_real_loader = DataLoader(dataset_test_real, shuffle=False, batch_size=1, num_workers=4)\n",
    "\n",
    "n_test_real = dataset_test_real.__len__()\n",
    "\n",
    "best_model.eval()\n",
    "case_list = []\n",
    "class_list = []\n",
    "P0_list = []\n",
    "P1_list = []\n",
    "P2_list = []\n",
    "for i in range(n_test_real):\n",
    "    img, _ = dataset_test_real.__getitem__(i)\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    case_name = dataset_test_real.imgs[i].split('/')[-1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        yhat = best_model(img)\n",
    "        yhat_np = yhat.max(1)[1].detach().cpu().numpy()\n",
    "        yhat_score = torch.softmax(yhat,-1).detach().cpu().numpy()\n",
    "\n",
    "        case_list.append(case_name)\n",
    "        class_list.append(yhat_np[0])\n",
    "        P0_list.append(yhat_score[0,0])\n",
    "        P1_list.append(yhat_score[0,1])\n",
    "        P2_list.append(yhat_score[0,2])\n",
    "\n",
    "submission_dict = {\n",
    "    \"case\": case_list,\n",
    "    \"class\": class_list,\n",
    "    \"P0\": P0_list,\n",
    "    \"P1\": P1_list,\n",
    "    \"P2\": P2_list,\n",
    "}\n",
    "\n",
    "submission_df = pd.DataFrame(submission_dict, columns=['case', 'class', 'P0', 'P1', 'P2'])\n",
    "\n",
    "submission_df.to_csv(f\"{experiment_name}_TEAMNAME.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [Pytorch Lightning](https://github.com/Lightning-AI/lightning)\n",
    "2. [pytorch-image-models;timm](https://github.com/rwightman/pytorch-image-models)\n",
    "3. [DRAC2022 submission example](https://github.com/zhuanjiao2222/DRAC2022)\n",
    "4. [DRAC2022 official web site](https://drac22.grand-challenge.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
